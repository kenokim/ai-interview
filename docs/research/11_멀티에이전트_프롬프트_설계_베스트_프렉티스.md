# **협업의 설계: 멀티 에이전트 시스템의 프롬프트 디자인에 대한 연구 기반 가이드**

### **Executive Summary**

본 보고서는 멀티 에이전트 시스템(Multi-Agent Systems, MAS)에서의
프롬프트 설계 모범 사례에 대한 포괄적이고 증거 기반의 분석을 제공합니다.
이 문서는 기본적인 프롬프트 엔지니어링을 넘어, 협력적 AI를 조율하는
과정에서 발생하는 고유한 복잡성을 해결하는 데 중점을 둡니다. 본 보고서는
MAS에서 프롬프트가 단순히 지시 사항이 아니라, 전문화된 에이전트의
정체성을 정의하고, 복잡한 워크플로우를 구조화하며, 정교한 추론을
가능하게 하고, 시스템의 신뢰성과 보안을 보장하는 근본적인 아키텍처
도구임을 입증할 것입니다. 주요 학술 연구 및 산업 사례 연구에서 종합한
핵심 결과에는 역할-목표-배경(Role-Goal-Backstory) 프레임워크를 통한
에이전트 전문화의 필요성, 작업 분해에서 오케스트레이터 프롬프트의 결정적
역할, 구조화된 통신 프로토콜의 필수성, 그리고 환각을 완화하고 성능을
향상시키기 위한 자기 검증 및 계층적 추론과 같은 고급 기법의 힘이
포함됩니다. 이 가이드는 AutoGen, CrewAI, LangGraph에 대한 실행 가능한
전략과 프레임워크별 예제를 제공하여, 개발자와 연구자들이 차세대 지능형
멀티 에이전트 애플리케이션을 견고하게 구축할 수 있도록 지원합니다.

## **섹션 1: 에이전트 정체성의 청사진으로서의 프롬프트**

멀티 에이전트 시스템의 효용성은 개별 구성 요소의 세심한 설계에서
시작됩니다. 프롬프트는 각 에이전트의 목적, 능력, 그리고 개성을 정의하는
헌법과 같은 역할을 하며, 이는 의미 있는 협업을 위한 전제 조건입니다. 이
섹션에서는 개별 에이전트의 정체성을 확립하는 데 있어 프롬프트가 어떻게
근본적인 역할을 수행하는지 탐구합니다.

### **1.1. 일반화보다 전문화의 필요성** {#일반화보다-전문화의-필요성}

복잡한 문제는 관리 가능한 단위로 분해하여 전문화된 에이전트가 처리할 때
가장 효과적으로 해결됩니다.^1^ 모든 것을 처리하는 단일의 거대 에이전트는
과도한 도구와 지나치게 광범위한 컨텍스트로 인해 혼란을 겪고 성능 저하를
초래하는 경향이 있습니다.^4^ 반면, 멀티 에이전트 시스템은 다양한 전문
관점을 통합하여 결과물을 개선하고 편향을 줄이는 데 강점을 보입니다.^1^

연구와 실제 적용 사례는 대규모 언어 모델(LLM)이 일반적인 프롬프트보다
특정 작업에 맞춤화된 프롬프트를 받았을 때 훨씬 더 나은 성능을 보인다는
것을 일관되게 입증합니다.^5^ 이 원칙은 에이전트의 지식 기반 및 메모리를
포함한 모든 구성 요소에 적용되며, 이들 역시 작업별로 특화되어야
합니다.^5^ 예를 들어, 구직 지원 에이전트 개발 사례에서는 핵심 과제가
코딩이 아니라, 에이전트와 작업 명세를 명확한 언어로 정의하는 것이었으며,
이는 전문화의 중요성을 강조합니다.^6^ 이처럼 복잡한 문제를 해결하기 위한
첫 단계는 문제를 더 작은 하위 작업으로 나누고, 각 작업을 전담할 고도로
전문화된 에이전트를 설계하는 것입니다.

### **1.2. 역할-목표-배경 프레임워크: 효과적인 페르소나 설계** {#역할-목표-배경-프레임워크-효과적인-페르소나-설계}

CrewAI와 같은 플랫폼에서 널리 활용되는
역할-목표-배경(Role-Goal-Backstory) 프레임워크는 전문화된 에이전트를
구체화하는 구조적인 접근법을 제공합니다. 이 세 가지 요소는 에이전트의
시스템 프롬프트에 인코딩되어, 그 행동을 지시하는 일관된 페르소나를
형성합니다.^7^ 이 상세한 페르소나는 에이전트의 \'두뇌\'인 LLM을
활성화하는 프롬프트 템플릿의 핵심 구성 요소가 됩니다.^8^

- **역할 (Role):** 에이전트의 기능과 전문 분야를 정의합니다 (예:
  > \"시니어 금융 분석가\").^7^ 역할은 구체적이고 현실 세계의 직업과
  > 일치하도록 설정하는 것이 효과적입니다.^7^

- **목표 (Goal):** 에이전트의 의사결정을 안내하고 품질 기준을 포함하는
  > 개별적이고 결과 중심적인 목적입니다 (예: \"회사의 재무 건전성을
  > 분석하여 투자 추천 보고서 작성\").^7^

- **배경 (Backstory):** 에이전트의 문제 해결 접근 방식에 영향을 미치는
  > 맥락, 경험, 그리고 개성을 제공합니다 (예: \"변동성이 큰 시장에서
  > 15년간 근무하며 신중하고 데이터 중심적인 접근으로 명성을 쌓은 노련한
  > 분석가\").^7^

이러한 페르소나의 구축은 단순히 성능 향상을 넘어, 시스템 전체의
회복탄력성을 높이는 중요한 기제로 작용합니다. 모호한 작업을 받은 일반
에이전트는 문자 그대로의 텍스트 외에는 해석의 틀이 없어 실패하거나
중복된 작업을 수행하기 쉽습니다.^10^ 반면, \"공감적 대응에 특화된 노련한
위기 커뮤니케이션 책임자\"와 같이 상세한 페르소나를 프롬프트로 받은
에이전트는 추가적인 맥락을 활용할 수 있습니다.^7^ 이 에이전트는 모호한
지시에 직면했을 때 자신의 \'배경\'과 \'역할\'을 사용하여 사용자의 의도를
추론하고 적절한 어조와 전략을 채택할 수 있습니다. 결과적으로, 페르소나는
암묵적인 오류 처리 및 해석 계층으로 기능하여 에이전트를 더 견고하게
만들고 시스템 전체의 취약성을 줄입니다. 프롬프트의 서사적 요소가
시스템의 기능적 회복탄력성에 직접적으로 기여하는 것입니다.

### **1.3. 추론 촉매제로서의 역할극** {#추론-촉매제로서의-역할극}

프롬프트를 통해 상세한 역할이나 페르소나를 부여하는 행위는 단순히
외형적인 설정에 그치지 않고, 기반 LLM의 추론 능력을 측정 가능하게
향상시킵니다. 학술 연구에 따르면, 전략적으로 설계된 역할극 프롬프트는
다양한 추론 벤치마크에서 표준적인 제로샷(zero-shot) 접근법을 일관되게
능가하는 성능을 보였습니다.^11^ \"Better Zero-Shot Reasoning with
Role-Play Prompting\" 논문은 역할극이 암묵적인 사고의
연쇄(Chain-of-Thought, CoT)를 유발하여 더 효과적인 추론 경로를
생성한다고 주장합니다.^11^

이 기법은 복잡한 문제 해결을 위해 LLM에게 물리학자, 수학자 등 다양한
전문가 역할을 부여하는 CoMM(Collaborative Multi-agent,
Multi-reasoning-path)과 같은 협업 프레임워크의 기초가 됩니다.^12^
역할극은 에이전트가 특정 지식 영역에 집중하고, 해당 분야의 전문가처럼
사고하도록 유도함으로써 문제 해결의 정확성과 깊이를 더합니다.

### **1.4. 에이전트의 세계관 정의: 컨텍스트, 도구, 제약 조건** {#에이전트의-세계관-정의-컨텍스트-도구-제약-조건}

에이전트의 초기 프롬프트는 그것이 작동하는 \'세계\'에 대한 완전하고
일관된 그림을 제시해야 합니다.^14^ 여기에는 접근 가능한 리소스, 사용할
수 있는 도구, 그리고 운영상의 경계를 명확히 정의하는 것이 포함됩니다.

- **완전한 컨텍스트 제공:** 에이전트는 개발자의 머릿속에 있는 정보를
  > 추론할 수 없으므로, 관련된 모든 정보를 프롬프트에 명시적으로
  > 제공해야 합니다.^14^

- **구조화된 도구 사용:** 프롬프트 내에서 도구는 명확한 이름, 설명,
  > 매개변수와 함께 잘 문서화되어야 모델이 올바른 작업을 위해 적절한
  > 도구를 선택하는 데 도움이 됩니다.^15^ 모델의 혼란을 피하기 위해
  > 프롬프트는 도구의 실제 동작과 일관되어야 합니다.^14^

- **명시적 제약 조건 설정:** \"브라우저 기반의 제한된 환경에서
  > 작동함\"과 같은 운영상의 제약 조건과 안전 가이드라인을 명확히
  > 정의하여 위험을 최소화해야 합니다.^15^

에이전트가 사용할 수 있는 도구가 많아질수록 의사결정 과정이 복잡해져
LLM에 가해지는 인지 부하가 증가하고, 잘못된 도구를 선택할 확률이
높아집니다. 멀티 에이전트 설계는 문제를 전문화된 에이전트의 작업으로
분해하도록 권장하며 ^1^, 이는 각 에이전트가 제한적이고 관련성 높은 도구
집합을 가져야 함을 의미합니다.^2^ 모든 것을 처리하는 단일 에이전트는
너무 많은 도구 때문에 혼란을 겪는 흔한 실패 모드를 보입니다.^4^ 따라서
에이전트 페르소나(역할과 목표)의 범위는 도구 집합의 범위와 긴밀하게
결합되어야 한다는 중요한 프롬프트 설계 원칙이 도출됩니다. 이 둘의
불일치(예: \'데이터 분석가\' 에이전트에게 코드 배포 도구를 부여하는
경우)는 프롬프트의 \'세계관\'에 모호성을 만들어 오류를 유발합니다.
에이전트의 프롬프트 설계와 도구 집합 설계는 독립적인 활동이 아니라, 함께
개발되어야 하는 상호 의존적인 과정입니다.

## **섹션 2: 오케스트레이션과 협업 프롬프트의 원칙**

이 섹션에서는 개별 에이전트 설계를 넘어 멀티 에이전트 시스템의 핵심
과제인 효과적인 팀워크를 촉진하는 프롬프트 설계로 논의를 전환합니다.
오케스트레이터 에이전트와 시스템 전체를 관장하는 통신 프로토콜 설계에
초점을 맞춥니다.

### **2.1. 위임의 기술: 오케스트레이터 프롬프트 설계** {#위임의-기술-오케스트레이터-프롬프트-설계}

많은 멀티 에이전트 아키텍처에서 리더 또는 오케스트레이터 에이전트는 가장
중요한 구성 요소입니다. 그 주된 역할은 복잡한 사용자 쿼리를 작업자
에이전트를 위한 일관되고, 실행 가능하며, 중복되지 않는 하위 작업들로
분해하는 것입니다.^4^ 전적으로 오케스트레이터의 프롬프트에 의해 좌우되는
이 분해의 품질은 시스템 성능의 주요 결정 요인입니다.

앤트로픽(Anthropic)의 멀티 에이전트 연구 시스템 개발은 강력한 실제
사례를 제공합니다. 그들은 \"반도체 부족 현상 조사\"와 같은 단순하고 짧은
지시가 너무 모호하여 중복 작업과 잘못된 작업 해석을 초래한다는 것을
발견했습니다.^10^

따라서 효과적인 위임 프롬프트는 오케스트레이터가 각 하위 에이전트에게
다음을 제공하도록 지시해야 합니다:

1.  **명확한 목표:** 이 하위 작업의 구체적인 목표는 무엇인가?

2.  **정의된 출력 형식:** 결과는 어떻게 구조화되어야 하는가?

3.  **도구 및 소스에 대한 지침:** 어떤 리소스를 사용해야 하는가?

4.  **명확한 작업 경계:** 중복을 방지하기 위한 이 하위 작업의 정확한
    > 범위는 무엇인가? ^10^

이러한 설계에는 근본적인 트레이드오프가 존재합니다. 오케스트레이터의
위임 프롬프트가 더 정교하고 상세할수록, 작업자 에이전트의 프롬프트는 더
단순하고 모듈화될 수 있습니다. 앤트로픽의 경험은 모호한 작업을 지시하는
\'단순한\' 오케스트레이터가 모호성을 해석할 수 있는 \'똑똑한\' 작업자를
필요로 한다는 것을 보여주며, 이는 비효율적이고 실패하기 쉽습니다.^10^
반면, 확장 규칙과 작업 경계 정의가 포함된 상세한 프롬프트로 안내되는
\'똑똑한\' 오케스트레이터는 문제 분해라는 무거운 인지 작업을 수행합니다.
이는 작업자 에이전트가 \"이 특정 데이터셋을 분석하고 평균값을 JSON
형식으로 반환하라\"와 같이 매우 단순하고 고도로 집중된 프롬프트로 설계될
수 있게 합니다. 이러한 단순하고 전문화된 작업자 에이전트는 더 신뢰할 수
있고, 디버깅이 용이하며, 다양한 워크플로우에서 재사용성이 높습니다.^1^
따라서 시스템의 복잡성은 제거되는 것이 아니라, 의식적으로
오케스트레이터의 프롬프트로 이전됩니다. 이는 하나의 복잡한
오케스트레이터 프롬프트에 집중적으로 투자하여 단순하고 재사용 가능한
작업자 프롬프트 생태계를 가능하게 하는 전략적인 아키텍처 결정입니다.

### **2.2. 복잡성에 따른 노력 확장** {#복잡성에-따른-노력-확장}

에이전트는 주어진 작업에 적절한 노력의 양을 판단하는 데 어려움을
겪습니다. 간단한 사실 확인 임무에 과도한 조사를 하거나, 복잡한 분석에
자원을 부족하게 투입할 수 있습니다. 이는 프롬프트를 통해 제어되어야
합니다.

가장 좋은 방법은 오케스트레이터의 프롬프트 내에 명시적인 확장 규칙을
포함하는 것입니다. 예를 들어, \"간단한 사실 확인에는 1개의 에이전트와
3-10회의 도구 호출을 사용하라. 직접적인 비교에는 2-4개의 에이전트와 각각
10-15회의 호출을 사용하라. 복잡한 연구에는 명확하게 책임이 분담된 10개
이상의 에이전트를 사용하라\"와 같은 지침을 포함할 수 있습니다.^10^ 이는
흔한 실패 원인인 자원 과잉 투자를 방지합니다.

### **2.3. 에이전트 간 통신 구조화** {#에이전트-간-통신-구조화}

에이전트들이 효과적으로 협력하기 위해서는 그들이 교환하는 정보가
구조화되고 예측 가능해야 합니다. 프롬프트는 입출력에 대해 일관된 데이터
형식을 강제해야 합니다.

- **구조화된 형식 사용:** 프롬프트에서 JSON이나 XML과 유사한 태그와 같은
  > 형식을 사용하도록 강제합니다. 이는 출력을 신뢰할 수 있고 다른
  > 에이전트가 프로그래밍 방식으로 쉽게 파싱할 수 있게 만듭니다.^15^

- **예시 제공 (Few-Shot):** 작업 설명 프롬프트에 직접 예시를 포함하여
  > 원하는 출력 형식을 명확히 전달합니다.^18^

- **\'계획 모드\'와 \'실행 모드\' 분리:** 프롬프트에 계획과 실행을 위한
  > 별도의 단계를 구조화하여 실행 전에 신중한 계획을 장려합니다.^15^

### **2.4. 상호작용 토폴로지 및 고급 협업 패턴 설계** {#상호작용-토폴로지-및-고급-협업-패턴-설계}

에이전트들이 연결되는 방식과 상호작용의 순서(즉, \'토폴로지\')는
프롬프트에 의해 안내되는 오케스트레이션 로직에 의해 정의되는 중요한 설계
선택입니다.

- **일반적인 토폴로지:**

  - **순차적(Sequential):** 에이전트 A의 출력이 에이전트 B의 입력이
    > 됩니다.^1^

  - **계층적/오케스트레이터-작업자(Hierarchical/Orchestrator-Worker):**
    > 중앙 에이전트가 전문 작업자에게 작업을 위임합니다.^2^

  - **토론/협력적 논의(Debate/Collaborative Discussion):** 여러
    > 에이전트가 문제에 대해 논의하여 해결책을 개선하고, 편향과 환각을
    > 줄입니다.^1^

- **CoMM 프레임워크:** 복잡한 문제 해결을 위한 정교한 연구 기반
  > 패턴입니다. 이 프레임워크는 LLM이 물리학자, 수학자, 요약가 등 다양한
  > 역할을 가진 전문가 팀으로 행동하도록 프롬프트합니다. 핵심 혁신은 각
  > 역할극 에이전트에게 서로 다른 *추론 경로*(예: 물리학 대 수학에
  > 맞춤화된 퓨샷 예시)를 할당하는 것이며, 이는 매우 효과적인 것으로
  > 밝혀졌습니다.^12^ 실험 결과, 이러한 협력적 다중 경로 접근법은 대학
  > 수준의 과학 문제에서 강력한 기준선들을 크게 능가하는 성능을
  > 보였습니다.^13^

에이전트 상호작용 토폴로지의 선택은 단순히 워크플로우 효율성에 관한 것이
아니라, 출력의 신뢰성을 향상시키고 환각을 완화하는 강력한 도구입니다.
단일 에이전트는 자신의 추론에 도전할 외부 관점이 없기 때문에 환각과
편향에 취약합니다.^1^ 멀티 에이전트 시스템은 본질적으로 다양한 관점을
도입합니다.^1^ \'토론\' ^13^이나 \'검토자\' 에이전트 ^1^와 같은
토폴로지는 이러한 다양성을 명시적으로 활용합니다. 한 에이전트는 해결책을
생성하도록 프롬프트되고, 다른 에이전트는 그 해결책을 비판하도록
프롬프트됩니다. 이러한 적대적이거나 협력적인 검토 과정은 시스템이
스스로를 교정하도록 강제합니다. \'비평가\' 에이전트의 프롬프트는 내장된
사실 확인기 또는 논리 검증기 역할을 합니다. 따라서 프롬프트를 통해
명시적인 검토 루프를 가진 토폴로지를 설계하는 것이 단일 에이전트를 위한
\'완벽한\' 프롬프트를 만들려는 시도보다 환각을 줄이는 데 더 견고한
전략입니다. 신뢰성은 단일 프롬프트 내의 지시뿐만 아니라, 프롬프트에 의해
정의된

*상호작용*에서 비롯됩니다.

## **섹션 3: 신뢰성 및 추론 향상을 위한 고급 기법**

이 섹션에서는 단순한 지시 따르기를 넘어, 정교한 추론과 자가 수정 능력을
멀티 에이전트 워크플로우에 직접 구축하는 최첨단의 연구 기반 프롬프트
기법을 탐구합니다. 이를 통해 더 견고하고 자율적인 시스템을 만들 수
있습니다.

### **3.1. 멀티 에이전트 컨텍스트에서의 고급 추론 패턴** {#멀티-에이전트-컨텍스트에서의-고급-추론-패턴}

- **사고의 연쇄(Chain-of-Thought, CoT)와 그 이상:** \"단계별로 생각해
  > 보자\"와 같은 CoT는 단일 LLM의 추론을 향상시키는 기본 기술이지만
  > ^24^, 그 힘은 MAS에서 증폭됩니다. 한 에이전트가 CoT 계획을
  > 생성하도록 프롬프트되고, 이 계획이 다른 에이전트에게 전달되어 실행될
  > 수 있습니다.

- **계층적 사고의 연쇄(Layered Chain-of-Thought, Layered-CoT):** 이
  > 새로운 프레임워크는 추론 과정을 체계적으로 여러 계층으로 분할합니다.
  > 핵심 혁신은 각 계층이 다음 단계로 진행하기 전에 외부 검증(예: 다른
  > 전문 에이전트나 도구에 의한) 및 선택적 사용자 피드백을 거친다는
  > 점입니다.^25^ 이는 \'검증자\' 에이전트가 각 단계에서 \'제안자\'
  > 에이전트의 출력을 확인하도록 프롬프트될 수 있는 MAS에 본질적으로
  > 적합하며, 중간 추론의 정확성과 투명성을 보장합니다.^25^

### **3.2. 자가 수정 루프 구현: 성찰과 검증** {#자가-수정-루프-구현-성찰과-검증}

환각 현상을 방지하고 정확성을 높이기 위해, 에이전트들은 자신이나 다른
에이전트의 작업을 비판하고 개선하도록 프롬프트될 수 있습니다. 이는
시스템 내에 반복적인 피드백 루프를 생성합니다.

- **성찰 (Self-Refine):** 이 기법은 2단계 프롬프트 과정을 포함합니다.
  > 먼저, 에이전트가 초기 응답을 생성합니다. 둘째, \'성찰자\'
  > 에이전트(또는 후속 단계의 동일 에이전트)에게 원래의 질의와 초기
  > 응답이 포함된 새로운 프롬프트가 주어지며, 이를 비판하도록
  > 요청받습니다: \"이 응답의 강점은 무엇인가? 약점은 무엇인가? 어떻게
  > 개선될 수 있는가?\".^26^ 이 성찰은 개선된 최종 답변을 생성하는 데
  > 사용됩니다. 이 기법은 코드 생성부터 창의적 글쓰기에 이르기까지
  > 광범위한 작업에서 효과적인 것으로 나타났습니다.^26^

- **자기 검증 (Self-Verification):** 이 기법은 추론 작업에 엄격한 오류
  > 수정 메커니즘을 추가합니다.^27^ 여러 후보 해결책을 생성한 다음,
  > 결론이 원래의 맥락과 일치하는지 확인하는 검증 단계를 프롬프트합니다.
  > 예를 들어, 원래 문제의 조건을 가리고 생성된 해결책이 이를 정확하게
  > 예측할 수 있는지 확인하는 방식입니다.^28^ 이 과정은 에이전트가
  > 자신의 추론 과정을 검증하도록 강제함으로써 정확성을
  > 향상시킵니다.^28^

- **검증의 연쇄 (Chain-of-Verification, CoVe):** CoT와 유사하지만, 추론
  > 단계를 생성하는 대신 에이전트는 자신의 초기 응답을 평가하고 개선하기
  > 위해 일련의 검증 질문을 생성하고 답변하도록 프롬프트됩니다.^27^
  > MAS에서는 한 에이전트가 응답을 생성하고, 다른 에이전트가 검증 질문을
  > 생성하고 답변하도록 프롬프트될 수 있습니다.

### **3.3. 원칙 기반 프롬프트: 에이전트가 스스로 규칙을 정의하다** {#원칙-기반-프롬프트-에이전트가-스스로-규칙을-정의하다}

이는 멀티 에이전트 시스템이 주요 작업을 해결하기 위한 최적의 지침
원칙(즉, 프롬프트의 핵심)을 먼저 생성하도록 하는 고도로 발전된
전략입니다.

- **\"PRINCIPLE-BASED PROMPTING\" 논문 증거:** 텍스트 분류 작업을 위해,
  > 여러 LLM 에이전트가 독립적으로 데모 샘플을 분석하고 클래스 간 구별을
  > 위한 후보 \'원칙\'을 생성하도록 프롬프트됩니다. 이 후보들은 \'최종
  > 결정자\' 에이전트에게 전달되어 최종 원칙 집합으로 통합됩니다. 이
  > 최종 집합은 실제 작업을 수행할 \'분류자\' 에이전트의 프롬프트에
  > 사용됩니다.^23^

- **성능:** 프롬프트 생성을 위한 이러한 멀티 에이전트 접근법은 표준
  > 제로샷 프롬프트에 비해 상당한 성능 향상(매크로 F1 점수 기준 최대
  > 19.37%)을 달성했으며, CoT와 같은 다른 강력한 기준선들을
  > 능가했습니다.^23^

이러한 고급 기법들은 프롬프트 설계의 패러다임 전환을 의미합니다. 인간이
정적이고 포괄적인 지침을 제공하는 대신, 추론, 검증, 심지어 전략 생성의
동적이고 내부적인 프로세스를 시작하는 메타-지시를 제공하게 됩니다. 표준
프롬프트는 에이전트에게 무엇을 해야 할지 *알려주는* 것입니다. 성찰 및
검증과 같은 기법은 에이전트에게 자신의 작업을 확인하도록 *요청하는*
것입니다. 이는 지시에서 자기 성찰로의 전환입니다. 원칙 기반 프롬프트는
한 걸음 더 나아가, 시스템에 자신의 지침(원칙)을 *생성*하도록 과제를
부여합니다. 이는 시스템이 문제에 대해 추론하는 최선의 방법에 대해
추론하는 메타-인지의 한 형태입니다. 이는 인간 프롬프트 엔지니어의 역할이
모든 세부 사항을 지정하는 \'마이크로매니저\'에서 에이전트가 따를
메타-인지 프로세스(검증 루프, 원칙 생성 워크플로우)를 설계하는 \'시스템
아키텍트\'로 진화하고 있음을 시사합니다. 프롬프트는 완전한 \'작업
목록\'이 아닌 \'프로세스 시작자\'가 됩니다.

이러한 기법들이 품질을 향상시키는 반면, 토큰 사용량과 지연 시간 측면에서
상당한 비용이 발생합니다. 이를 사용할지 여부는 기술적인 문제일 뿐만
아니라 경제적인 결정이기도 합니다. 멀티 에이전트 시스템은 근본적으로
단일 에이전트가 할 수 있는 것보다 더 많은 토큰을 소비하여 문제를
해결합니다.^10^ 성찰, 검증 또는 계층적 CoT 루프의 각 단계는 추가적인 LLM
호출이며, 이는 토큰 소비를 더욱 증가시킵니다. 따라서 이러한 신뢰성 향상
패턴의 구현은 작업의 가치에 의해 정당화되어야 합니다.^10^ 중요도가 낮은
콘텐츠 생성 작업은 다단계 검증 프로세스의 비용을 정당화하지 못할 수
있지만, 중요도가 높은 의료 진단이나 재무 분석 작업은 그럴 가치가
있습니다. 이는 추론 및 검증 프롬프트의 복잡성이 작업의 중요도에 비례해야
한다는 중요한 설계 원칙으로 이어집니다. 프롬프트 설계는 원하는 정확성과
경제적 실행 가능성 사이의 균형을 맞춰야 합니다.

## **섹션 4: 프레임워크별 구현 가이드**

이 섹션에서는 앞서 논의된 원칙들을 실제 적용 사례에 기반하여 설명하며,
세 가지 주요 멀티 에이전트 시스템 프레임워크의 아키텍처 제약 및 기능
내에서 프롬프트를 설계하는 방법에 대한 상세한 예제와 분석을 제공합니다.

### **4.1. AutoGen: 대화형 에이전트를 위한 프롬프트** {#autogen-대화형-에이전트를-위한-프롬프트}

- **핵심 철학:** AutoGen은 자동화된 채팅을 통해 상호작용하는 \'대화 가능
  > 에이전트(conversable agents)\' 개념을 기반으로 구축되었습니다.^29^
  > 프롬프트는 에이전트 역할을 정의하고 이러한 대화를 시작하고 관리하는
  > 데 중점을 둡니다.

- **주요 프롬프트 구성 요소:**

  - **AssistantAgent:** 핵심 구성 요소는 에이전트의 역할, 전문성 및
    > 지침을 정의하는 system_message입니다.^19^ 역할-목표-배경
    > 프레임워크는 이곳에서 구현될 수 있습니다.

  - **UserProxyAgent:** 종종 인간 사용자의 프록시 역할을 하지만, 코드
    > 실행이나 대화 시작을 위해 구성될 수 있습니다. 이 에이전트의
    > 프롬프트는 일반적으로 초기 작업 메시지입니다.^30^

  - **ReAct 패턴:** AutoGen은 사고(Thought) -\> 행동(Action) -\> 행동
    > 입력(Action Input) -\> 관찰(Observation) 루프를 따르도록
    > 에이전트에게 명시적으로 지시하는 ReAct(\"Reason + Act\")
    > 프롬프트를 지원합니다.^32^ 이 구조화된 형식은 에이전트의 추론
    > 과정을 안내하기 위해 시스템 프롬프트 내에 정의됩니다.

### **4.2. CrewAI: 역할 기반 협업을 위한 고수준 추상화** {#crewai-역할-기반-협업을-위한-고수준-추상화}

- **핵심 철학:** CrewAI는 공통의 목표를 달성하기 위해 협력하는 역할극
  > 에이전트를 위해 설계되었습니다.^5^ 이는 \'누가\'(에이전트)와
  > \'무엇을\'(작업) 정의하는 데 중점을 둔 고수준의 선언적 API를
  > 제공합니다.

- **주요 프롬프트 구성 요소:**

  - **Agent:** role, goal, backstory에 의해 정의됩니다. 이러한 고수준
    > 매개변수는 내부적으로 상세한 시스템 프롬프트로 컴파일됩니다.^7^
    > 프레임워크는 전문화를 위해 이러한 요소를 효과적으로 작성하는
    > 방법에 대한 광범위한 지침을 제공합니다.^7^

  - **Task:** description(에이전트에 대한 상세 지침)과
    > expected_output(원하는 결과 형식의 명확한 정의)으로 정의됩니다.^7^
    > 작업 설명의 품질이 가장 중요합니다.^7^

  - **프롬프트 사용자 정의:** CrewAI는 개발자가 필요할 때 세부적인
    > 제어를 할 수 있도록 사용자 정의 prompts.json 파일을 제공하여 기본
    > 프롬프트 템플릿(예: 도구 사용 또는 구조화된 출력용)을 재정의할 수
    > 있게 합니다.^20^

### **4.3. LangGraph: 상태 기반 워크플로우를 통한 세분화된 제어** {#langgraph-상태-기반-워크플로우를-통한-세분화된-제어}

- **핵심 철학:** LangGraph는 멀티 에이전트 시스템을 순환 그래프 또는
  > 상태 기계로 취급합니다.^36^ 이는 가장 낮은 수준의 추상화를 제공하여
  > 개발자에게 워크플로우에 대한 완전한 제어권을 부여하며, 프롬프트는
  > 노드 내에서 공유 상태 객체를 처리하고 업데이트하는 데 사용됩니다.

- **주요 프롬프트 구성 요소:**

  - **상태 객체(State Object):** 워크플로우의 현재 상태(예: messages,
    > intermediate_steps)를 보유하는 중앙 딕셔너리입니다.^37^

  - **노드(Nodes):** 상태에 대해 작동하는 함수 또는 LCEL 실행 가능
    > 객체입니다. 프롬프트(PromptTemplate, ChatPromptTemplate)는 이러한
    > 노드 *내부*에서 상태를 처리하고 다음에 무엇을 할지 결정하는 데
    > 사용됩니다.^38^

  - **조건부 엣지(Conditional Edges):** 노드의 출력(프롬프트에 의해
    > 구동됨)은 그래프를 다음 노드로 라우팅하는 데 사용됩니다. 예를
    > 들어, 노드 내의 프롬프트는 LLM에게 도구를 호출할지 또는 종료할지를
    > 결정하도록 요청할 수 있으며, 조건부 엣지는 해당 문자열 출력에 따라
    > 흐름을 지시합니다.^37^ 이를 통해 프롬프트 로직에 의해 정의되는
    > 매우 동적이고 복잡한 워크플로우가 가능해집니다.

### **4.4. 프롬프트 철학 비교 분석** {#프롬프트-철학-비교-분석}

다음 표는 세 프레임워크의 프롬프트 아키텍처를 비교 분석하여, 추상화와
제어 사이의 균형점을 명확히 보여줍니다.

| 프레임워크    | 핵심 프롬프트 철학                                                                        | 주요 프롬프트 기본 요소                                                      | 강점                                                                      | 이상적인 사용 사례                                                                  |
|---------------|-------------------------------------------------------------------------------------------|------------------------------------------------------------------------------|---------------------------------------------------------------------------|-------------------------------------------------------------------------------------|
| **AutoGen**   | 대화형, 코드 중심 오케스트레이션. 에이전트를 자동화된 채팅에 참여하는 대화 파트너로 취급. | AssistantAgent(system_message), UserProxyAgent(message), ReAct 프롬프트 패턴 | 유연한 대화 흐름, 코드 실행 및 인간-루프 통합에 강함.                     | 동적 작업 해결, 코드 생성 및 디버깅, 인간의 피드백이 필요한 워크플로우.             |
| **CrewAI**    | 선언적, 역할 기반 위임. 에이전트를 직무 기술서를 가진 전문가 팀으로 취급.                 | Agent(role, goal, backstory), Task(description, expected_output)             | 빠른 개발, 고수준 추상화, 에이전트 전문화의 강력한 강제.                  | 마케팅 캠페인, 연구 보고서 생성 과정 등 인간 팀 구조를 모방하는 워크플로우.         |
| **LangGraph** | 상태 기반, 명시적 제어. 에이전트 상호작용을 상태 기계의 노드와 엣지로 모델링.             | StateGraph(State), graph.add_node(), graph.add_conditional_edge()            | 워크플로우의 모든 단계에 대한 완전한 제어, 순환 및 복잡한 로직 구현 용이. | 신뢰성이 높은 에이전트, 인간-루프 승인, 복잡한 오류 처리, 맞춤형 에이전트 아키텍처. |

이 비교 분석은 개발자나 연구자가 프로젝트의 특정 요구 사항에 따라 올바른
도구를 선택하는 데 도움을 줍니다. 예를 들어, \"모든 단계를 세밀하게
제어해야 하므로 LangGraph가 최적이다\" 또는 \"협업 워크플로우를 신속하게
프로토타이핑해야 하므로 CrewAI가 이상적이다\"와 같은 정보에 입각한
결정을 내릴 수 있습니다. 따라서 이 표는 서술적 정보를 의사결정 도구로
전환하여 상당한 실용적 가치를 제공합니다.

## **섹션 5: 프롬프트 기반 시스템의 보안 및 디버깅**

이 마지막 섹션에서는 멀티 에이전트 시스템 배포의 중요한 운영 과제를
다루며, 프롬프트 설계가 안전한 시스템을 만들고 비결정적 환경에서
효과적인 디버깅을 가능하게 하는 데 어떻게 중심적인 역할을 하는지
집중적으로 살펴봅니다.

### **5.1. 아키텍처 설계를 통한 프롬프트 인젝션 완화** {#아키텍처-설계를-통한-프롬프트-인젝션-완화}

- **위협:** 멀티 에이전트 시스템에서 프롬프트 인젝션은 하나의 감염된
  > 에이전트가 다른 에이전트를 \'감염\'시킬 수 있기 때문에 더 큰 위협이
  > 됩니다.^40^ 악의적인 지시는 외부 데이터 소스(간접 인젝션)에서
  > 비롯되어 에이전트 간 통신을 통해 전파될 수 있습니다.

- **핵심 원칙:** 보안은 모든 가능한 입력을 소독하려는 시도가 아니라,
  > 신뢰할 수 없는 데이터를 격리하고 이를 처리하는 에이전트의 능력을
  > 제한하도록 시스템을 설계함으로써 달성됩니다. 이 아키텍처는
  > 프롬프트와 워크플로우 설계를 통해 정의됩니다.^41^

- **보안 지향 프롬프트 설계 패턴:**

  - **계획 후 실행 (Plan-Then-Execute):** 오케스트레이터 에이전트는
    > 도구를 호출하거나 외부 데이터를 수집하기 *전에* 전체 실행 계획을
    > 생성하도록 프롬프트됩니다. 이 계획은 이후 엄격하게 실행됩니다.
    > 감염된 도구의 *콘텐츠*가 후속 단계로 흘러 들어갈 수는 있지만,
    > 사전에 승인된 *행동 순서*를 변경할 수는 없습니다.^42^

  - **권한 있는 에이전트와 격리된 에이전트:** 프롬프트에 의해 정의된 두
    > 종류의 에이전트로 시스템을 설계합니다. \'권한 있는\'
    > 오케스트레이터는 신뢰할 수 없는 외부 데이터를 절대 다루지 않도록
    > 하는 프롬프트를 가집니다. 이러한 데이터를 포함하는 작업은
    > \'격리된\' 하위 에이전트에게 위임합니다. 하위 에이전트의
    > 프롬프트는 데이터를 처리하도록 허용하지만, 그 출력을 안전하고
    > 구조화된 형식(예: 불리언 또는 엄격한 스키마를 가진 JSON 객체)으로
    > 엄격하게 제한하여, 주 워크플로우로 반환되기 전에 효과적으로
    > 소독합니다.^42^

이러한 접근 방식은 멀티 에이전트 시스템의 보안이 통신 아키텍처의 창발적
속성이며, 이는 프롬프트에 의해 결정된다는 점을 보여줍니다. 핵심 취약점은
신뢰할 수 없는 데이터가 의사결정 능력을 가진 구성 요소(LLM)로 유입되는
것입니다. \'계획 후 실행\' 및 \'권한/격리\' 패턴은 근본적으로 이 정보
흐름을 제어하는 것에 관한 것입니다. \'계획\'이나 \'격리\'는 별도의
코드가 아니라, 에이전트에게 프롬프트에 의해 부과된 행동 제약입니다.
따라서 전체 시스템의 보안은 외부 데이터 처리 및 위임 방식을 지시하는
오케스트레이터 프롬프트의 몇 줄에 달려 있을 수 있습니다. 프롬프트
엔지니어링은 기능적 요구사항일 뿐만 아니라 주요 보안 통제 수단입니다.

### **5.2. 비결정적 시스템의 관찰 가능성 및 디버깅** {#비결정적-시스템의-관찰-가능성-및-디버깅}

- **과제:** 멀티 에이전트 시스템의 디버깅은 동일한 입력에도 불구하고 그
  > 행동이 동적이고 비결정적이기 때문에 악명이 높습니다.^17^ 시스템이 왜
  > 실패했는지 정확한 추론의 연쇄를 보지 않고는 이해하기가 종종
  > 불가능합니다.

- **모범 사례: 전체 프로덕션 추적:** 포괄적인 로깅 및 추적을 구현하는
  > 것은 선택 사항이 아니라 핵심 요구 사항입니다. LangSmith와 같은
  > 도구는 이를 위해 설계되었으며, 각 실행에 대한 에이전트 상호작용,
  > 도구 호출, LLM 입출력의 전체 체인에 대한 가시성을 제공합니다.^17^

- **디버깅을 위한 프롬프트 설계:**

  - **에이전트처럼 생각하기:** 효과적으로 디버깅하려면 개발자는
    > 에이전트가 프롬프트를 어떻게 해석할지에 대한 정신 모델을 구축해야
    > 합니다. 정확한 프롬프트와 도구를 사용하여 에이전트 단계를
    > 시뮬레이션하는 것은 실패 모드를 드러내는 중요한 디버깅
    > 관행입니다.^10^

  - **구조화된 출력 강제:** 섹션 2에서 언급했듯이, JSON이나 XML과 같은
    > 구조화된 출력을 강제하는 프롬프트는 에이전트의 상태와 통신 기록을
    > 훨씬 쉽게 파싱하고 디버깅할 수 있게 만듭니다.^15^

  - **반복적 개선:** 프롬프트 엔지니어링은 반복적인 과정입니다. 추적
    > 도구를 사용하여 에이전트 행동을 관찰하고, 프롬프트의 결함을
    > 식별하며, 이를 개선하고 신속하게 재테스트해야 합니다.^15^

프롬프트의 명확성과 구조는 시스템을 얼마나 쉽게 디버깅할 수 있는지를
직접적으로 결정합니다. 디버깅의 주요 과제는 에이전트가 실수를 저질렀을
때의 \'마음 상태\'를 이해하는 것입니다.^17^ 자유 형식의 비구조적인
텍스트 출력을 허용하는 프롬프트는 이 상태를 불투명하고 분석하기 어렵게
만듭니다. 반면, 명시적인

사고 및 행동 필드가 있는 ReAct 루프나 JSON 응답과 같이 엄격하고 구조화된
출력을 강제하는 프롬프트는 에이전트의 상태를 명시적이고 기계가 읽을 수
있게 만듭니다. 이 구조화된 출력은 LangSmith와 같은 추적 도구에 의해 쉽게
로깅, 파싱 및 분석될 수 있습니다. 따라서 디버깅을 염두에 두고 프롬프트를
설계하는 것(즉, 구조를 강제하는 것)은 개발 및 유지보수 수명 주기 동안
상당한 이점을 제공하는 선제적인 조치입니다. 프롬프트 설계에 들이는 초기
노력은 미래의 디버깅 노력을 줄여줍니다.

## **결론 및 향후 전망**

본 보고서는 멀티 에이전트 시스템의 프롬프트 설계 모범 사례를 체계적으로
분석하여, 프롬프트를 핵심 아키텍처 구성 요소로 확립했습니다. 우리는
역할-목표-배경 프레임워크를 사용한 개별 전문 에이전트 정의에서부터
상세한 위임, 구조화된 통신, 그리고 신중하게 설계된 상호작용 토폴로지를
통한 협업 조율에 이르기까지 논의를 전개했습니다. 또한, 자기 검증 및
계층적 CoT와 같이 메타-인지적 추론을 시스템에 내장하여 신뢰성을 높이고
환각을 완화하는 연구 기반의 고급 기법들을 탐구했습니다. 이러한 원칙들은
AutoGen, CrewAI, LangGraph와 같은 주요 프레임워크의 실제 적용 사례를
통해 구체화되었으며, 보안 및 디버깅이라는 중요한 영역 내에서
맥락화되었습니다.

전반적인 추세는 정적이고 단일적인 프롬프트에서 벗어나, 프롬프트에 의해
시작되고 관리되는 동적이고, 협력적이며, 자가 수정이 가능한 *프로세스*를
설계하는 방향으로 나아가고 있습니다. 이 분야의 미래는 더 높은 수준의
추상화와 자동화에 있습니다. 반복적인 최적화 과정을 통해 최적의
프롬프트와 에이전트 토폴로지를 자동으로 발견하는 것을 목표로 하는
\*\*멀티 에이전트 시스템 탐색(Multi-Agent System Search, MASS)\*\*과
같은 프레임워크는 다음 개척지를 대표합니다.^43^ 이러한 도구들이 성숙함에
따라, 인간 엔지니어의 역할은 프롬프트 제작자에서 그러한 프롬프트를
설계하는 자동화된 시스템의 아키텍트로 계속 진화할 것이며, 이는 협력적
AI가 달성할 수 있는 것의 경계를 더욱 확장시킬 것입니다.

#### 참고 자료

1.  Multi-Agent System - A B Vijay Kumar - Medium, 7월 19, 2025에
    > 액세스,
    > [[https://abvijaykumar.medium.com/multi-agent-architectures-e09c53c7fe0d]{.underline}](https://abvijaykumar.medium.com/multi-agent-architectures-e09c53c7fe0d)

2.  Is Your AI Strategy Stuck on Prompt Engineering? How Multi-Agent
    > Systems Can Transform Your Business - AIM Councils, 7월 19, 2025에
    > 액세스,
    > [[https://councils.aimmediahouse.com/is-your-ai-strategy-stuck-on-prompt-engineering-how-multi-agent-systems-can-transform-your-business/]{.underline}](https://councils.aimmediahouse.com/is-your-ai-strategy-stuck-on-prompt-engineering-how-multi-agent-systems-can-transform-your-business/)

3.  (PDF) Fine-Tuning and Prompt Engineering of LLMs, for the Creation
    > of Multi-Agent AI for Addressing Sustainable Protein Production
    > Challenges - ResearchGate, 7월 19, 2025에 액세스,
    > [[https://www.researchgate.net/publication/393022653_Fine-Tuning_and_Prompt_Engineering_of_LLMs_for_the_Creation_of_Multi-Agent_AI_for_Addressing_Sustainable_Protein_Production_Challenges]{.underline}](https://www.researchgate.net/publication/393022653_Fine-Tuning_and_Prompt_Engineering_of_LLMs_for_the_Creation_of_Multi-Agent_AI_for_Addressing_Sustainable_Protein_Production_Challenges)

4.  Orchestrating Multi-Agent AI Systems: When Should You Expand to
    > Using Multiple Agents?, 7월 19, 2025에 액세스,
    > [[https://www.willowtreeapps.com/craft/multi-agent-ai-systems-when-to-expand]{.underline}](https://www.willowtreeapps.com/craft/multi-agent-ai-systems-when-to-expand)

5.  Designing LLM-Based Agents: Key Principles --- Part 1 \| by Craig
    > Li, Ph.D - Medium, 7월 19, 2025에 액세스,
    > [[https://medium.com/binome/designing-llm-based-agents-key-principles-part-1-7e8c6fe3ddaf]{.underline}](https://medium.com/binome/designing-llm-based-agents-key-principles-part-1-7e8c6fe3ddaf)

6.  Lessons Learned from Building Real-World Multi-Agent Systems \| by
    > Brunelli Stefano, 7월 19, 2025에 액세스,
    > [[https://medium.com/@brunelli.stefano.eu/lessons-learned-from-building-real-world-multi-agent-systems-32a4d5f06fbb]{.underline}](https://medium.com/@brunelli.stefano.eu/lessons-learned-from-building-real-world-multi-agent-systems-32a4d5f06fbb)

7.  Crafting Effective Agents - CrewAI, 7월 19, 2025에 액세스,
    > [[https://docs.crewai.com/en/guides/agents/crafting-effective-agents]{.underline}](https://docs.crewai.com/en/guides/agents/crafting-effective-agents)

8.  LLM Agents - Prompt Engineering Guide, 7월 19, 2025에 액세스,
    > [[https://www.promptingguide.ai/research/llm-agents]{.underline}](https://www.promptingguide.ai/research/llm-agents)

9.  Agents - CrewAI Documentation, 7월 19, 2025에 액세스,
    > [[https://docs.crewai.com/en/concepts/agents]{.underline}](https://docs.crewai.com/en/concepts/agents)

10. How we built our multi-agent research system - Anthropic, 7월 19,
    > 2025에 액세스,
    > [[https://www.anthropic.com/engineering/built-multi-agent-research-system]{.underline}](https://www.anthropic.com/engineering/built-multi-agent-research-system)

11. Better Zero-Shot Reasoning with Role-Play Prompting - ACL Anthology,
    > 7월 19, 2025에 액세스,
    > [[https://aclanthology.org/2024.naacl-long.228.pdf]{.underline}](https://aclanthology.org/2024.naacl-long.228.pdf)

12. CoMM: Collaborative multi-agent, multi-reasoning-path prompting for
    > complex problem solving - Amazon Science, 7월 19, 2025에 액세스,
    > [[https://www.amazon.science/publications/comm-collaborative-multi-agent-multi-reasoning-path-prompting-for-complex-problem-solving]{.underline}](https://www.amazon.science/publications/comm-collaborative-multi-agent-multi-reasoning-path-prompting-for-complex-problem-solving)

13. CoMM: Collaborative Multi-Agent, Multi-Reasoning \... - ACL
    > Anthology, 7월 19, 2025에 액세스,
    > [[https://aclanthology.org/2024.findings-naacl.112.pdf]{.underline}](https://aclanthology.org/2024.findings-naacl.112.pdf)

14. How to build your Agent: 11 prompting techniques for better AI
    > agents - Augment Code, 7월 19, 2025에 액세스,
    > [[https://www.augmentcode.com/blog/how-to-build-your-agent-11-prompting-techniques-for-better-ai-agents]{.underline}](https://www.augmentcode.com/blog/how-to-build-your-agent-11-prompting-techniques-for-better-ai-agents)

15. Prompt Engineering for AI Agents - PromptHub, 7월 19, 2025에 액세스,
    > [[https://www.prompthub.us/blog/prompt-engineering-for-ai-agents]{.underline}](https://www.prompthub.us/blog/prompt-engineering-for-ai-agents)

16. Multi-Agent Systems: The Future of AI Collaboration - Saigon
    > Technology, 7월 19, 2025에 액세스,
    > [[https://saigontechnology.com/blog/multi-agent-systems/]{.underline}](https://saigontechnology.com/blog/multi-agent-systems/)

17. How and when to build multi-agent systems - LangChain Blog, 7월 19,
    > 2025에 액세스,
    > [[https://blog.langchain.com/how-and-when-to-build-multi-agent-systems/]{.underline}](https://blog.langchain.com/how-and-when-to-build-multi-agent-systems/)

18. Best practices for prompt engineering with the OpenAI API, 7월 19,
    > 2025에 액세스,
    > [[https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-the-openai-api]{.underline}](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-the-openai-api)

19. Getting Started with AutoGen 0.4, 7월 19, 2025에 액세스,
    > [[https://www.gettingstarted.ai/autogen-multi-agent-workflow-tutorial/]{.underline}](https://www.gettingstarted.ai/autogen-multi-agent-workflow-tutorial/)

20. Customizing Prompts - CrewAI Documentation, 7월 19, 2025에 액세스,
    > [[https://docs.crewai.com/en/guides/advanced/customizing-prompts]{.underline}](https://docs.crewai.com/en/guides/advanced/customizing-prompts)

21. 멀티모달 프롬프트 설계 \| Generative AI on Vertex AI - Google Cloud,
    > 7월 19, 2025에 액세스,
    > [[https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/design-multimodal-prompts?hl=ko]{.underline}](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/design-multimodal-prompts?hl=ko)

22. Prompt Engineering in Multi-Agent Systems with KaibanJS - Hugging
    > Face, 7월 19, 2025에 액세스,
    > [[https://huggingface.co/blog/darielnoel/llm-prompt-engineering-kaibanjs]{.underline}](https://huggingface.co/blog/darielnoel/llm-prompt-engineering-kaibanjs)

23. A Principle-Based Multi-Agent Prompting Strategy for Text
    > Classification - arXiv, 7월 19, 2025에 액세스,
    > [[https://arxiv.org/html/2502.07165v1]{.underline}](https://arxiv.org/html/2502.07165v1)

24. \[Prompt Engineering\] Best Practices of Prompt Engineering -
    > 데이터와 인공지능 훑어보기 - 티스토리, 7월 19, 2025에 액세스,
    > [[https://yumdata.tistory.com/427]{.underline}](https://yumdata.tistory.com/427)

25. \[2501.18645\] Layered Chain-of-Thought Prompting for Multi-Agent
    > LLM Systems: A Comprehensive Approach to Explainable Large
    > Language Models - arXiv, 7월 19, 2025에 액세스,
    > [[https://arxiv.org/abs/2501.18645]{.underline}](https://arxiv.org/abs/2501.18645)

26. Reflexion Prompting - Ryan & Matt Data Science, 7월 19, 2025에
    > 액세스,
    > [[https://ryanandmattdatascience.com/reflexion-prompting/]{.underline}](https://ryanandmattdatascience.com/reflexion-prompting/)

27. Introduction to Self-Criticism Prompting Techniques for LLMs, 7월
    > 19, 2025에 액세스,
    > [[https://learnprompting.org/docs/advanced/self_criticism/introduction]{.underline}](https://learnprompting.org/docs/advanced/self_criticism/introduction)

28. Self-Verification Prompting: Enhancing LLM Accuracy in Reasoning
    > \..., 7월 19, 2025에 액세스,
    > [[https://learnprompting.org/docs/advanced/self_criticism/self_verification]{.underline}](https://learnprompting.org/docs/advanced/self_criticism/self_verification)

29. How to use the Microsoft Autogen framework to Build AI Agents? -
    > ProjectPro, 7월 19, 2025에 액세스,
    > [[https://www.projectpro.io/article/autogen/1139]{.underline}](https://www.projectpro.io/article/autogen/1139)

30. Getting Started \| AutoGen 0.2 - Open Source at Microsoft, 7월 19,
    > 2025에 액세스,
    > [[https://microsoft.github.io/autogen/0.2/docs/Getting-Started/]{.underline}](https://microsoft.github.io/autogen/0.2/docs/Getting-Started/)

31. A practical guide for using AutoGen in software applications \| by
    > Clint Goodman - Medium, 7월 19, 2025에 액세스,
    > [[https://clintgoodman27.medium.com/a-practical-guide-for-using-autogen-in-software-applications-8799185d27ee]{.underline}](https://clintgoodman27.medium.com/a-practical-guide-for-using-autogen-in-software-applications-8799185d27ee)

32. ReAct \| AutoGen 0.2 - Microsoft Open Source, 7월 19, 2025에 액세스,
    > [[https://microsoft.github.io/autogen/0.2/docs/topics/prompting-and-reasoning/react/]{.underline}](https://microsoft.github.io/autogen/0.2/docs/topics/prompting-and-reasoning/react/)

33. A collection of examples that show how to use CrewAI framework to
    > automate workflows. - GitHub, 7월 19, 2025에 액세스,
    > [[https://github.com/crewAIInc/crewAI-examples]{.underline}](https://github.com/crewAIInc/crewAI-examples)

34. CrewAI Step-by-Step \| Complete Course for Beginners - YouTube, 7월
    > 19, 2025에 액세스,
    > [[https://www.youtube.com/watch?v=kBXYFaZ0EN0&pp=0gcJCdgAo7VqN5tD]{.underline}](https://www.youtube.com/watch?v=kBXYFaZ0EN0&pp=0gcJCdgAo7VqN5tD)

35. Crew AI Crash Course (Step by Step) \| by ProspexAI - Medium, 7월
    > 19, 2025에 액세스,
    > [[https://medium.com/@tarekeesa7/crew-ai-crash-course-step-by-step-e8536e2414be]{.underline}](https://medium.com/@tarekeesa7/crew-ai-crash-course-step-by-step-e8536e2414be)

36. Insights and Learnings from Building a Complex Multi-Agent System :
    > r/LangChain - Reddit, 7월 19, 2025에 액세스,
    > [[https://www.reddit.com/r/LangChain/comments/1byz3lr/insights_and_learnings_from_building_a_complex/]{.underline}](https://www.reddit.com/r/LangChain/comments/1byz3lr/insights_and_learnings_from_building_a_complex/)

37. LangGraph - LangChain Blog, 7월 19, 2025에 액세스,
    > [[https://blog.langchain.dev/langgraph/]{.underline}](https://blog.langchain.dev/langgraph/)

38. Mastering Prompt Engineering for LangChain, LangGraph, and AI Agent
    > Applications, 7월 19, 2025에 액세스,
    > [[https://becomingahacker.org/mastering-prompt-engineering-for-langchain-langgraph-and-ai-agent-applications-e26d85a55f13]{.underline}](https://becomingahacker.org/mastering-prompt-engineering-for-langchain-langgraph-and-ai-agent-applications-e26d85a55f13)

39. LangChain & LangGraph Tutorial: In-Depth Chat Memory & Prompts -
    > Triumph.ai, 7월 19, 2025에 액세스,
    > [[https://www.triumphai.in/post/learn-langchain-langgraph-in-depth-chat-memory-prompts]{.underline}](https://www.triumphai.in/post/learn-langchain-langgraph-in-depth-chat-memory-prompts)

40. \[2410.07283\] Prompt Infection: LLM-to-LLM Prompt Injection within
    > Multi-Agent Systems, 7월 19, 2025에 액세스,
    > [[https://arxiv.org/abs/2410.07283]{.underline}](https://arxiv.org/abs/2410.07283)

41. The Sandboxed Mind --- Principled Isolation Patterns for
    > Prompt‑Injection‑Resilient LLM Agents \| by Adnan Masood, PhD. \|
    > Jun, 2025 \| Medium, 7월 19, 2025에 액세스,
    > [[https://medium.com/@adnanmasood/the-sandboxed-mind-principled-isolation-patterns-for-prompt-injection-resilient-llm-agents-c14f1f5f8495]{.underline}](https://medium.com/@adnanmasood/the-sandboxed-mind-principled-isolation-patterns-for-prompt-injection-resilient-llm-agents-c14f1f5f8495)

42. Design Patterns for Securing LLM Agents against Prompt Injections,
    > 7월 19, 2025에 액세스,
    > [[https://simonwillison.net/2025/Jun/13/prompt-injection-design-patterns/]{.underline}](https://simonwillison.net/2025/Jun/13/prompt-injection-design-patterns/)

43. \[2502.02533\] Multi-Agent Design: Optimizing Agents with Better
    > Prompts and Topologies, 7월 19, 2025에 액세스,
    > [[https://arxiv.org/abs/2502.02533]{.underline}](https://arxiv.org/abs/2502.02533)

44. Multi-Agent Design: Optimizing Agents with Better Prompts and
    > Topologies - Hugging Face, 7월 19, 2025에 액세스,
    > [[https://huggingface.co/papers/2502.02533]{.underline}](https://huggingface.co/papers/2502.02533)
