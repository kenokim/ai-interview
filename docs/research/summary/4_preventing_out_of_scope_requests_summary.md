# LangGraph 기반 프로덕션급 챗봇을 위한 의도치 않은 사용자 요청 방지 전략 요약

이 문서는 LangGraph를 사용하여 프로덕션 환경에서 발생할 수 있는 '의도치 않은 사용자 요청'에 대응하기 위한 다층적 방어(Defense-in-Depth) 아키텍처를 제시합니다. 이는 기능 범위를 벗어나는 요청, 악의적인 공격, 운영상의 실패 등 다양한 위협을 체계적으로 관리하는 것을 목표로 합니다.

## 1부: 기반 계층 - 선제적 입력 관리 (입력 게이트키핑)

핵심 로직에 도달하기 전에 사용자 입력을 검토, 분류, 정화하는 첫 번째 방어선입니다.

-   **라우터-디스패처 패턴**: 그래프의 진입점에 '라우터' 노드를 두어 사용자 의도를 **in-scope, out-of-scope, needs_clarification** 등으로 먼저 분류합니다. `with_structured_output`과 Pydantic 모델을 사용하여 라우팅 결정을 신뢰할 수 있는 구조화된 형태로 만들고, `add_conditional_edges`를 통해 각기 다른 처리 경로로 동적으로 분기합니다.
-   **개체명 추출**: 쿼리에서 핵심 정보(개체명, Entity)를 추출하여 요청이 시스템의 도메인 내에서 의미 있고 실행 가능한지 검증하는 '의미론적 유효성 검사'를 수행합니다.
-   **전처리 안전 가드레일**: `Guardrails AI`와 같은 전문 라이브러리를 사용하여 유해성, PII(개인식별정보), 프롬프트 인젝션과 같은 명백한 위협을 시스템의 가장 초기 단계에서 차단합니다.

## 2부: 아키텍처 핵심 - 제어되고 회복력 있는 워크플로우

에이전트의 실행 경로를 제어 가능하고, 예측 가능하며, 실패에 대해 회복력을 갖도록 만드는 아키텍처 패턴입니다.

-   **계층적 오류 처리**:
    -   **레벨 1 (격리)**: 각 노드를 `try-except` 블록으로 감싸 기본적인 오류를 처리합니다.
    -   **레벨 2 (점진적 성능 저하)**: `RunnableWithFallbacks`를 사용하여 주 실행 단위 실패 시 더 강력한 대체 모델이나 체인으로 작업을 재시도합니다.
    -   **레벨 3 (자가 수정)**: 발생한 오류 메시지 자체를 LLM에 다시 피드백하여 에이전트가 자율적으로 문제를 해결하도록 유도하는 '자가 수정 루프'를 구현합니다.
-   **슈퍼바이저 에이전트 패턴**: 중앙의 '슈퍼바이저' 에이전트가 전문화된 '워커' 에이전트 팀을 조율하는 방식입니다. 이는 '최소 권한 원칙'을 적용하여 각 워커가 필요한 도구에만 접근하도록 제한함으로써 시스템의 보안과 모듈성을 극대화합니다.
-   **Human-in-the-Loop (HIL)**: 되돌릴 수 없거나 리스크가 큰 작업을 수행하기 전에, `interrupt()` 함수를 사용하여 그래프 실행을 일시 중지하고 인간의 승인이나 편집을 요청하는 최종 안전장치를 마련합니다.

## 3부: 최종 검문소 - 엄격한 출력 평가

응답이 사용자에게 전달되기 직전에 최종 품질 및 안전 검사를 수행하는 마지막 방어선입니다.

-   **'평가자(Evaluator)' 노드 패턴**: 그래프의 END 직전에 '평가자' 노드를 두어, 생성된 최종 응답이 사실에 기반하는지, 관련성이 있는지, 유해하지 않은지를 평가합니다. 평가 결과에 따라 응답을 사용자에게 전달할지, 아니면 재시도/폐기할지를 조건부로 결정합니다.
-   **LLM-as-a-Judge**: 더 강력한 별개의 LLM을 '심판'으로 사용하여 응답의 품질을 자동으로 채점하는 기법입니다. `DeepEval`이나 `LangSmith`와 같은 프레임워크를 활용하여 구현할 수 있습니다.
-   **관찰 가능성 플랫폼**: `LangSmith`와 같은 도구를 사용하여 프로덕션 환경의 실패 사례를 체계적으로 추적, 디버깅하고, 이를 평가 데이터셋으로 전환하여 지속적으로 시스템을 개선하는 '플라이휠 효과'를 구축합니다.

## 4부: 고급 전략 - 동적 그래프 생성

-   **플래너-실행자 모델**: 모든 경로가 미리 정의된 정적 그래프 대신, 각 사용자 쿼리에 맞춰 '플래너' 에이전트가 최적화된 실행 계획(DAG)을 먼저 생성합니다. 그 후 '실행자'가 이 계획을 임시 LangGraph로 동적으로 컴파일하고 실행합니다. 이는 의도치 않은 경로가 애초에 생성되지 않도록 하여 내재적인 안전성을 확보하는 선제적 방어 모델입니다.

## 결론

견고한 에이전트 시스템은 단일 솔루션이 아닌, 입력 관리, 워크플로우 제어, 출력 평가 등 여러 방어 계층이 결합된 결과물입니다. 이 보고서에서 제안된 심층 방어 모델은 LangGraph를 사용하여 예측 불가능성을 관리하고, 신뢰할 수 있으며, 목적에 부합하는 프로덕션급 AI 에이전트를 구축하기 위한 종합적인 프레임워크를 제공합니다. 