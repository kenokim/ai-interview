# LangGraph 스트리밍 기능 기술 요구사항 (TRD)

## 1. LangGraph 스트리밍 기능이란?

LangGraph의 스트리밍(Streaming)은 전체 그래프(Graph) 실행이 완료될 때까지 기다리지 않고, 각 노드(에이전트)가 실행될 때마다 발생하는 중간 결과와 상태를 실시간으로 받아볼 수 있는 기능입니다.

기존의 `invoke` 방식이 모든 계산이 끝난 후 최종 결과만 반환하는 것과 달리, `stream` 방식은 다음과 같은 정보를 실행과 동시에 지속적으로 전달합니다.

-   현재 실행 중인 노드의 이름
-   해당 노드에서 생성된 데이터 (출력)
-   그래프의 현재 상태 (State)

이를 통해 클라이언트는 LangGraph 내부에서 어떤 작업이 어떤 순서로 진행되고 있는지 실시간으로 관찰할 수 있습니다.

## 2. AI 면접 서비스에 스트리밍이 필요한 이유

현재 텍스트 기반의 AI 면접 서비스에서도 스트리밍 기능은 사용자 경험과 개발 편의성을 크게 향상시킬 수 있습니다.

-   사용자 경험 개선 (UX Enhancement): AI가 사용자의 답변을 평가하고 다음 질문을 생성하기까지는 여러 단계(답변 평가, 후속 질문 유형 결정, 질문 생성 등)를 거칩니다. 스트리밍을 사용하면 "답변을 분석하고 있습니다...", "후속 질문을 생각 중입니다..."와 같은 현재 진행 상태를 UI에 표시하여, 사용자가 마냥 기다리는 것이 아니라 시스템이 능동적으로 작동하고 있음을 인지시켜 지루함과 불안감을 줄일 수 있습니다.

-   디버깅 및 관찰 용이성 (Observability): 면접 흐름은 복잡한 Agent 상태에 따라 동적으로 결정됩니다. 스트리밍은 각 노드의 실행 과정과 데이터를 실시간으로 보여주므로, 개발자가 시스템의 내부 동작을 명확히 추적하고 예상치 못한 동작이 발생했을 때 원인을 신속하게 파악하는 데 매우 유용합니다.

## 3. 향후 음성 기능 연동 시 스트리밍의 중요성

음성 대화(Voice Interaction) 환경에서 스트리밍은 선택이 아닌 필수 기능이 됩니다. 그 이유는 다음과 같습니다.

-   '죽은 시간' (Dead Air) 최소화: 음성 대화에서 몇 초간의 침묵은 사용자에게 시스템 오류라는 인상을 주거나 대화의 흐름을 끊는 치명적인 요소입니다. 스트리밍을 사용하면, 최종 답변을 생성하는 도중에도 "흠, 흥미로운 답변이네요. 잠시만요..." 와 같은 담화 표지(filler)를 먼저 생성하여 TTS로 즉시 출력함으로써 어색한 침묵을 없애고 자연스러운 대화 경험을 만들 수 있습니다.

-   응답 지연 최소화 및 실시간 상호작용: 사용자는 AI의 전체 답변이 완성될 때까지 기다리고 싶어 하지 않습니다. 스트리밍을 활용하면 AI가 문장을 생성하는 대로 즉시 클라이언트에 전달하고, 클라이언트는 이를 TTS 엔진으로 보내 음성을 출력할 수 있습니다. 이는 AI가 긴 답변을 하더라도 첫 문장이 나오는 시간을 크게 단축시켜 거의 실시간에 가까운 상호작용을 구현하는 핵심 기술입니다.

-   자연스러운 대화 흐름 구현: 사람이 대화하듯, 첫 문장으로 답변을 시작하고 이어서 논리를 전개하는 방식의 구현이 가능해집니다. 이를 통해 전체 답변이 한 번에 딱딱하게 전달되는 것이 아니라, 자연스럽게 흘러가는 듯한 인상을 주어 면접의 몰입감을 높일 수 있습니다.
