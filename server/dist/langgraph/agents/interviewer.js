import { HumanMessage, AIMessage } from "@langchain/core/messages";
import { ChatGoogleGenerativeAI } from "@langchain/google-genai";
const supervisorPrompt = `ë‹¹ì‹ ì€ AI ë©´ì ‘ê´€ íŒ€ì„ ê´€ë¦¬í•˜ëŠ” ìŠˆí¼ë°”ì´ì €ì…ë‹ˆë‹¤. ëŒ€í™”ì˜ ë§¥ë½ì„ ë³´ê³  ë‹¤ìŒì— ì–´ë–¤ ì—ì´ì „íŠ¸ë¥¼ í˜¸ì¶œí• ì§€ ê²°ì •í•©ë‹ˆë‹¤.

[ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸]
- greeting_agent: ë©´ì ‘ ì‹œì‘ ì¸ì‚¬ë¥¼ ë‹´ë‹¹í•©ë‹ˆë‹¤. (ì°¸ê³ : ì´ ì—ì´ì „íŠ¸ëŠ” ëŒ€í™”ê°€ ì²˜ìŒ ì‹œì‘ë  ë•Œ ì‹œìŠ¤í…œì— ì˜í•´ ë‹¨ í•œ ë²ˆë§Œ í˜¸ì¶œë©ë‹ˆë‹¤. ë‹¹ì‹ ì€ ì´ ì—ì´ì „íŠ¸ë¥¼ ë‹¤ì‹œ í˜¸ì¶œí•´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤.)
- conversation_agent: ì§€ì›ìì™€ ê¸°ìˆ  ì§ˆë¬¸ì´ë‚˜ ì¼ë°˜ ëŒ€í™”ë¥¼ ì´ì–´ê°‘ë‹ˆë‹¤.
- FINISH: ì§€ì›ìì˜ ë‹µë³€ì„ ê¸°ë‹¤ë¦¬ê¸° ìœ„í•´ ì›Œí¬í”Œë¡œìš°ë¥¼ ì¼ì‹œ ì¤‘ì§€í•©ë‹ˆë‹¤.

[ë¼ìš°íŒ… ê·œì¹™]
ì£¼ì–´ì§„ ìƒíƒœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ê·œì¹™ì— ë”°ë¼ ê°€ì¥ ì í•©í•œ ì—ì´ì „íŠ¸ *í•˜ë‚˜ë§Œ* ê²°ì •í•˜ì„¸ìš”.

- **ë©´ì ‘ ì‹œì‘ ë˜ëŠ” ëŒ€í™” ì§„í–‰**:
  - 'interview_stage'ê°€ "Greeting" ë˜ëŠ” "Questioning"ì´ê³ , ë§ˆì§€ë§‰ ë©”ì‹œì§€ê°€ ì§€ì›ìì˜ ì‘ë‹µ(HumanMessage)ì´ë¼ë©´, ë©´ì ‘ì„ ê³„ì† ì§„í–‰í•´ì•¼ í•©ë‹ˆë‹¤.
  - ğŸ‘‰ **conversation_agent**ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.

- **AIê°€ ë°©ê¸ˆ ì‘ë‹µí•œ ê²½ìš°**:
  - ë§ˆì§€ë§‰ ë©”ì‹œì§€ê°€ AIì˜ ì‘ë‹µ(AIMessage)ì´ë©´, ì§€ì›ìì˜ ë‹¤ìŒ ì…ë ¥ì„ ê¸°ë‹¤ë ¤ì•¼ í•©ë‹ˆë‹¤. (ì°¸ê³ : ì´ ê·œì¹™ì€ ì‹œìŠ¤í…œì— ì˜í•´ ìë™ìœ¼ë¡œ ì²˜ë¦¬ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.)
  - ğŸ‘‰ **FINISH**ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.

[ì¶œë ¥]
ë°˜ë“œì‹œ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ì˜ ë‹¨ì–´ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
conversation_agent, FINISH
`;
export const interviewerNode = async (state) => {
    console.log("ë©´ì ‘ê´€ ë…¸ë“œê°€ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.");
    const { proactive } = state;
    let message = "ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.";
    if (proactive) {
        const { trigger_event_type, metadata } = proactive;
        if (trigger_event_type === "USER_APPLIED") {
            message = `ì•ˆë…•í•˜ì„¸ìš”, ${metadata?.userName || 'ì§€ì›ì'}ë‹˜. ì§€ì›í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. ì§€ê¸ˆë¶€í„° AI ì—­ëŸ‰ ë©´ì ‘ì„ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤.`;
        }
        else if (trigger_event_type === "INTERVIEW_SCHEDULED") {
            message = `ì•ˆë…•í•˜ì„¸ìš”, ${metadata?.userName || 'ì§€ì›ì'}ë‹˜. ì˜ˆì•½í•˜ì‹  AI ì—­ëŸ‰ ë©´ì ‘ ì‹œê°„ì´ ë˜ì—ˆìŠµë‹ˆë‹¤. ì¤€ë¹„ë˜ì…¨ìœ¼ë©´ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤.`;
        }
    }
    return {
        ...state,
        messages: [...state.messages, new HumanMessage(message)],
        flow_control: {
            ...state.flow_control,
            next_worker: "supervisor"
        }
    };
};
export const supervisorNode = async (state) => {
    console.log("ğŸ§  [LangGraph] --- ìŠˆí¼ë°”ì´ì € ë…¸ë“œ ì‹œì‘ ---");
    const { messages, task } = state;
    console.log(`ğŸ” Supervisor: í˜„ì¬ ë©”ì‹œì§€ ê°œìˆ˜ = ${messages.length}`);
    if (messages.length > 0) {
        const lm = messages[messages.length - 1];
        console.log(`ğŸ” Supervisor: ë§ˆì§€ë§‰ ë©”ì‹œì§€(${lm instanceof AIMessage ? "AI" : "Human"}) = "${lm.content.toString().slice(0, 50)}"`);
    }
    // 1. ë©´ì ‘ ì‹œì‘ ì²˜ë¦¬ (ê°€ì¥ ë¨¼ì € í™•ì¸)
    if (messages.length === 0) {
        console.log("ìƒíƒœ: ëŒ€í™” ì—†ìŒ -> greeting_agent í˜¸ì¶œ");
        return {
            ...state,
            flow_control: {
                next_worker: "greeting_agent",
            },
        };
    }
    const lastMessage = messages[messages.length - 1];
    // 2. AIê°€ "ì§ˆë¬¸"ì„ í•œ ì§í›„ì—ë§Œ FINISH
    if (lastMessage instanceof AIMessage && task.interview_stage === "Questioning") {
        console.log(`ìƒíƒœ: Questioning / AI ë©”ì‹œì§€ -> FINISH (ì‚¬ìš©ì ì…ë ¥ ëŒ€ê¸°)`);
        return {
            ...state,
            flow_control: {
                next_worker: "FINISH",
            }
        };
    }
    // 2-1. AIê°€ "ì¸ì‚¬"ë¥¼ í•œ ì§í›„ì—ë„ FINISH (ì‚¬ìš©ìê°€ ì¤€ë¹„ ìƒíƒœë¥¼ í™•ì¸í•  ìˆ˜ ìˆë„ë¡)
    if (lastMessage instanceof AIMessage && task.interview_stage === "Greeting") {
        console.log(`ìƒíƒœ: Greeting / AI ë©”ì‹œì§€ -> FINISH (ì‚¬ìš©ì ì¤€ë¹„ ìƒíƒœ í™•ì¸ ëŒ€ê¸°)`);
        return {
            ...state,
            flow_control: {
                next_worker: "FINISH",
            }
        };
    }
    // 2-2. ì‚¬ìš©ìê°€ "ì‹œì‘" ë“±ìœ¼ë¡œ ì¤€ë¹„ë¥¼ ì•Œë¦° ê²½ìš° ë°”ë¡œ Questioning ë‹¨ê³„ë¡œ
    if (lastMessage instanceof HumanMessage && task.interview_stage === "Greeting") {
        console.log(`ìƒíƒœ: Greeting / Human ë©”ì‹œì§€ -> conversation_agent í˜¸ì¶œ`);
        return {
            ...state,
            flow_control: {
                next_worker: "conversation_agent",
            },
        };
    }
    // 3. ë©´ì ‘ ì¢…ë£Œ ìƒíƒœ ì²˜ë¦¬
    if (task.interview_stage === "Finished") {
        console.log("ìƒíƒœ: Finished -> FINISH");
        return {
            ...state,
            flow_control: {
                next_worker: "FINISH",
            }
        };
    }
    // 4. LLMì„ í†µí•œ ì§€ëŠ¥ì ì¸ ë¼ìš°íŒ… ê²°ì •
    const lastMessageType = lastMessage instanceof AIMessage ? "AI" : "Human";
    console.log(`ìƒíƒœ: ${task.interview_stage} / ${lastMessageType} ë©”ì‹œì§€ -> LLMìœ¼ë¡œ ë¼ìš°íŒ… ê²°ì •`);
    const model = new ChatGoogleGenerativeAI({
        model: "gemini-2.5-flash",
        temperature: 0,
        streaming: true,
    });
    const remainingQuestions = Math.max(0, (state.task.question_pool?.length || 0) - (state.task.questions_asked?.length || 0));
    const enhancedPrompt = supervisorPrompt
        .replace("{remaining_questions}", remainingQuestions.toString());
    console.log("LLM Supervisor í˜¸ì¶œ...");
    let response = "";
    const stream = await model.stream(enhancedPrompt);
    for await (const chunk of stream) {
        response += chunk.content;
    }
    const nextNode = response.toLowerCase().trim().replace(/"/g, "");
    console.log(`ğŸ§  [LangGraph] Supervisor ê²°ì •: ${nextNode}`);
    console.log("ğŸ§  [LangGraph] --- ìŠˆí¼ë°”ì´ì € ë…¸ë“œ ì¢…ë£Œ ---");
    return {
        ...state,
        flow_control: {
            ...state.flow_control,
            next_worker: nextNode,
        }
    };
};
//# sourceMappingURL=interviewer.js.map