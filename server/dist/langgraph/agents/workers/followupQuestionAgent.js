import { AIMessage } from "@langchain/core/messages";
import { ChatGoogleGenerativeAI } from "@langchain/google-genai";
const followupQuestionPrompt = `ë‹¹ì‹ ì€ ê¸°ìˆ  ë©´ì ‘ê´€ì…ë‹ˆë‹¤. í›„ë³´ìì˜ ì´ì „ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ, ë” ê¹Šì´ ìˆëŠ” ì´í•´ë¥¼ í™•ì¸í•˜ê¸° ìœ„í•œ í›„ì† ì§ˆë¬¸ì„ í•˜ë‚˜ ìƒì„±í•´ ì£¼ì„¸ìš”.

ì´ì „ ì§ˆë¬¸: {current_question}
í›„ë³´ì ë‹µë³€: {last_message}

ê·œì¹™:
- ì´ì „ ë‹µë³€ê³¼ ê´€ë ¨ëœ ì§ˆë¬¸ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
- ì§ˆë¬¸ì€ í•˜ë‚˜ë§Œ ìƒì„±í•©ë‹ˆë‹¤.
- ì§ˆë¬¸ ì™¸ì— ë‹¤ë¥¸ ë§ì€ í•˜ì§€ ë§ˆì„¸ìš”.

í›„ì† ì§ˆë¬¸:`;
export const followupQuestionAgent = async (state) => {
    console.log("ğŸ” Follow-up Question Agent generating follow-up...");
    const { messages, current_question } = state;
    const lastMessage = messages[messages.length - 1]?.content.toString() || "";
    const model = new ChatGoogleGenerativeAI({
        model: "gemini-2.0-flash",
        temperature: 0.7,
    });
    const formattedPrompt = followupQuestionPrompt
        .replace("{current_question}", current_question || "ì—†ìŒ")
        .replace("{last_message}", lastMessage);
    const response = await model.invoke(formattedPrompt);
    const question = response.content.toString();
    console.log(`ğŸ” Follow-up question generated: ${question}`);
    return {
        messages: [new AIMessage(question)],
        current_question: question,
        interview_stage: "Follow-up",
        next: "supervisor",
    };
};
//# sourceMappingURL=followupQuestionAgent.js.map