import { AIMessage } from "@langchain/core/messages";
import { ChatGoogleGenerativeAI } from "@langchain/google-genai";
const technicalQuestionPrompt = `ÎãπÏã†ÏùÄ Í∏∞Ïà† Î©¥Ï†ëÍ¥ÄÏûÖÎãàÎã§. Ï†úÍ≥µÎêú Î©¥Ï†ë Ïª®ÌÖçÏä§Ìä∏Î•º Î∞îÌÉïÏúºÎ°ú, ÌõÑÎ≥¥ÏûêÏóêÍ≤å Ìï† Í∏∞Ïà† ÏßàÎ¨∏ÏùÑ ÏÉùÏÑ±Ìï¥ Ï£ºÏÑ∏Ïöî.

Î©¥Ï†ë Ïª®ÌÖçÏä§Ìä∏:
- ÏßÅÎ¨¥: {jobRole}
- Í≤ΩÎ†•: {experience}
- Í∏∞Ïà† Ïä§ÌÉù: {interviewType}
- Ïù¥Ï†Ñ ÏßàÎ¨∏Îì§: {questions_asked}

Í∑úÏπô:
- Ïù¥Ï†ÑÍ≥º Í≤πÏπòÏßÄ ÏïäÎäî ÏÉàÎ°úÏö¥ ÏßàÎ¨∏ÏùÑ ÏÉùÏÑ±Ìï¥Ïïº Ìï©ÎãàÎã§.
- ÏßàÎ¨∏ÏùÄ ÌïòÎÇòÎßå ÏÉùÏÑ±Ìï©ÎãàÎã§.
- ÏßàÎ¨∏ Ïô∏Ïóê Îã§Î•∏ ÎßêÏùÄ ÌïòÏßÄ ÎßàÏÑ∏Ïöî.

ÏßàÎ¨∏:`;
export const technicalQuestionAgent = async (state) => {
    console.log("üîß Technical Question Agent generating question...");
    const { userContext, questions_asked } = state;
    const model = new ChatGoogleGenerativeAI({
        model: "gemini-2.0-flash",
        temperature: 0.7,
    });
    const formattedPrompt = technicalQuestionPrompt
        .replace("{jobRole}", userContext.jobRole)
        .replace("{experience}", userContext.experience)
        .replace("{interviewType}", userContext.interviewType)
        .replace("{questions_asked}", questions_asked.join(", ") || "ÏóÜÏùå");
    const response = await model.invoke(formattedPrompt);
    const question = response.content.toString();
    console.log(`üîß Technical question generated: ${question}`);
    return {
        messages: [new AIMessage(question)],
        current_question: question,
        questions_asked: [...questions_asked, question],
        interview_stage: "Questioning",
        next: "supervisor",
    };
};
//# sourceMappingURL=technicalQuestionAgent.js.map