import { StateGraph, END, START } from "@langchain/langgraph";
import { InterviewStateAnnotation, InterviewStateType } from "../types/state.js";
import { technicalQuestionAgent } from "./workers/technicalQuestionAgent.js";
import { followupQuestionAgent } from "./workers/followupQuestionAgent.js";
import { evaluateAnswer } from "./workers/evaluateAnswer.js";
import { HumanMessage, AIMessage, BaseMessage } from "@langchain/core/messages";
import { ChatGoogleGenerativeAI } from "@langchain/google-genai";
import { RunnableLambda } from "@langchain/core/runnables";
import { createSupervisorAgent } from "./supervisor/supervisorAgent.js";


const model = new ChatGoogleGenerativeAI({
  modelName: "gemini-2.0-flash",
  maxOutputTokens: 2048,
  temperature: 0.7,
  apiKey: process.env.GOOGLE_API_KEY,
});

/**
 * ìŠˆí¼ë°”ì´ì € ì—­í• ì„ í•˜ëŠ” Runnableì„ ìƒì„±í•©ë‹ˆë‹¤.
 * LLMì„ ì‚¬ìš©í•˜ì—¬ ë‹¤ìŒ í–‰ë™ì„ ê²°ì •í•©ë‹ˆë‹¤.
 * @param model ì‚¬ìš©í•  ChatGoogleGenerativeAI ëª¨ë¸
 * @returns ìŠˆí¼ë°”ì´ì € Runnable
 */
const createSupervisorRunnable = (model: ChatGoogleGenerativeAI) => {
  const supervisorChain = createSupervisorAgent(model);

  const route = async (state: InterviewStateType): Promise<{ next: string }> => {
    const { messages } = state;
    const lastMessage = messages[messages.length - 1] as HumanMessage;

    const response = await supervisorChain.invoke({
      chat_history: messages.map((msg: BaseMessage) => `${msg._getType()}: ${msg.content}`).join('\n'),
      input: lastMessage.content,
      interview_stage: state.task.interview_stage
    });

    // Handle complex response content from Gemini
    const responseContent = (
      Array.isArray(response.content)
        ? response.content.map(part => (part as any).text || '').join('')
        : response.content
    ) as string;
    
    const lowercasedContent = responseContent.toLowerCase();
    
    if (lowercasedContent.includes("finish")) {
      return { next: "FINISH" };
    } else if (lowercasedContent.includes("technical")) {
      return { next: "technical_question_agent" };
    } else if (lowercasedContent.includes("followup")) {
      return { next: "followup_question_agent" };
    } else {
      return { next: "Interviewer" };
    }
  };

  return new RunnableLambda({ func: route });
};


const supervisorAgent = createSupervisorRunnable(model);

// Supervisor ë…¸ë“œëŠ” ë‹¤ìŒì— ì–´ë–¤ ì›Œì»¤ë¥¼ ì‹¤í–‰í• ì§€ ê²°ì •í•˜ê³  ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
const supervisorNode = async (state: InterviewStateType): Promise<Pick<InterviewStateType, 'next'>> => {
  const supervisorResult = await supervisorAgent.invoke(state);
  return {
    next: supervisorResult.next,
  };
};

// Interviewer ë…¸ë“œëŠ” ì¼ë°˜ì ì¸ ëŒ€í™” íë¦„ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.
const interviewerNode = async (state: InterviewStateType) => {
  // ì´ ë…¸ë“œëŠ” í˜„ì¬ AIì˜ ì‘ë‹µì„ ìƒíƒœì— ì¶”ê°€í•˜ëŠ” ì—­í• ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
  // ì§€ê¸ˆì€ ë‹¤ìŒ ì§ˆë¬¸ì„ ìœ ë„í•˜ëŠ” ë©”ì‹œì§€ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
  return { messages: [new AIMessage("ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.")] };
};

// ë©”ì¸ ì¸í„°ë·° ê·¸ë˜í”„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
export function createInterviewGraph() {
  const graph = new StateGraph(InterviewStateAnnotation)
    .addNode("supervisor", supervisorNode)
    .addNode("Interviewer", interviewerNode)
    .addNode("technical_question_agent", technicalQuestionAgent)
    .addNode("followup_question_agent", followupQuestionAgent)
    .addNode("evaluate_answer", evaluateAnswer);

  // ê·¸ë˜í”„ì˜ ì‹œì‘ì ì„ supervisorë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
  graph.addEdge(START, "supervisor");

  // supervisorì˜ ê²°ì •ì— ë”°ë¼ ë‹¤ìŒ ë…¸ë“œë¡œ ë¶„ê¸°í•©ë‹ˆë‹¤.
  graph.addConditionalEdges(
    "supervisor",
    (state: InterviewStateType) => state.next,
    {
      Interviewer: "Interviewer",
      technical_question_agent: "technical_question_agent",
      followup_question_agent: "followup_question_agent",
      evaluate_answer: "evaluate_answer",
      FINISH: END,
    }
  );

  // ê° ì›Œì»¤ ë…¸ë“œê°€ ì‹¤í–‰ëœ í›„ì—ëŠ” ë‹¤ì‹œ supervisorë¡œ ëŒì•„ê°€ ë‹¤ìŒ í–‰ë™ì„ ê²°ì •í•©ë‹ˆë‹¤.
  graph.addEdge("Interviewer", "supervisor");
  graph.addEdge("technical_question_agent", "supervisor");
  graph.addEdge("followup_question_agent", "supervisor");
  graph.addEdge("evaluate_answer", "supervisor");

  return graph.compile();
}

// ì‚¬ìš©ì ì…ë ¥ì„ ì²˜ë¦¬í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
export async function processUserInput(
  graph: ReturnType<typeof createInterviewGraph>,
  state: InterviewStateType,
  userInput: string
): Promise<InterviewStateType> {
  console.log("ğŸ”„ Processing user input:", userInput);
  
  // ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ìƒíƒœì— ì¶”ê°€í•©ë‹ˆë‹¤.
  const updatedState = {
    ...state,
    messages: [...state.messages, new HumanMessage(userInput)],
    task: {
      ...state.task,
      current_answer: userInput
    },
    evaluation: {
      ...state.evaluation,
      turn_count: state.evaluation.turn_count + 1
    }
  };

  // ì—…ë°ì´íŠ¸ëœ ìƒíƒœë¡œ ê·¸ë˜í”„ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
  const result = await graph.invoke(updatedState);
  
  console.log("âœ… Graph execution completed");
  return result;
}

// ì¸í„°ë·°ë¥¼ ì‹œì‘í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
export async function startInterview(
  graph: ReturnType<typeof createInterviewGraph>,
  initialState?: Partial<InterviewStateType>
): Promise<InterviewStateType> {
  console.log("ğŸš€ Starting interview...");
  
  // ì´ˆê¸° ìƒíƒœë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
  const state: InterviewStateType = {
    user_context: initialState?.user_context || {
      user_id: "default_user",
      profile: {
        name: "Test User",
        experience_level: "mid-level",
        tech_stack: ["JavaScript", "React", "Node.js"],
        preferred_language: "JavaScript"
      }
    },
    messages: [new HumanMessage("ì•ˆë…•í•˜ì„¸ìš”, ë©´ì ‘ì„ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤.")],
    persona: initialState?.persona || {
      name: "Dr. Sarah Chen",
      role: "Senior Technical Interviewer",
      backstory: "A seasoned software engineer with 15+ years of experience in full-stack development and technical leadership.",
      style_guidelines: [
        "Ask follow-up questions to understand depth of knowledge",
        "Provide constructive feedback", 
        "Maintain professional yet approachable tone",
        "Focus on problem-solving approach over memorized answers"
      ],
      current_mood: "professional"
    },
    guardrails: {
      is_safe: true,
      fallback_count: 0
    },
    proactive: {
      trigger_event_type: "interview_start",
      trigger_event_id: "default",
      metadata: {}
    },
    flow_control: {
      next_worker: undefined
    },
    task: {
      interview_stage: "Greeting",
      question_pool: [
        {
          id: "js_closures",
          text: "Can you explain what closures are in JavaScript and provide an example?",
          category: "JavaScript",
          difficulty: "medium",
          expected_topics: ["lexical scoping", "function scope", "practical examples"]
        },
        {
          id: "react_hooks",
          text: "What are React Hooks and how do they differ from class components?",
          category: "React", 
          difficulty: "medium",
          expected_topics: ["useState", "useEffect", "lifecycle methods"]
        },
        {
          id: "async_js",
          text: "Explain the difference between Promises and async/await in JavaScript.",
          category: "JavaScript",
          difficulty: "medium",
          expected_topics: ["asynchronous programming", "error handling", "syntax differences"]
        }
      ],
      questions_asked: [],
      current_question: undefined,
      current_answer: undefined,
      agent_outcome: undefined,
      tool_outputs: undefined
    },
    evaluation: {
      turn_count: 0,
      last_user_feedback: undefined,
      task_successful: undefined,
      final_evaluation_summary: undefined,
      last_evaluation: undefined
    },
    next: 'supervisor', // Set the initial next node
    ...initialState
  };

  // ì¸í„°ë·°ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.
  const result = await graph.invoke(state);
  
  console.log("âœ… Interview started successfully");
  return result;
} 