import { AIMessage } from "@langchain/core/messages";
import { ChatGoogleGenerativeAI } from "@langchain/google-genai";
import {
  InterviewState,
} from "../../../types/state.js";

const technicalQuestionPrompt = `ë‹¹ì‹ ì€ ê¸°ìˆ  ë©´ì ‘ê´€ì…ë‹ˆë‹¤. ì œê³µëœ ë©´ì ‘ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ, í›„ë³´ìì—ê²Œ í•  ê¸°ìˆ  ì§ˆë¬¸ì„ ìƒì„±í•´ ì£¼ì„¸ìš”.

ë©´ì ‘ ì»¨í…ìŠ¤íŠ¸:
- ì§ë¬´: {jobRole}
- ê²½ë ¥: {experience}
- ê¸°ìˆ  ìŠ¤íƒ: {interviewType}
- ì´ì „ ì§ˆë¬¸ë“¤: {questions_asked}

ê·œì¹™:
- ì´ì „ê³¼ ê²¹ì¹˜ì§€ ì•ŠëŠ” ìƒˆë¡œìš´ ì§ˆë¬¸ì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.
- ì§ˆë¬¸ì€ í•˜ë‚˜ë§Œ ìƒì„±í•©ë‹ˆë‹¤.
- ì§ˆë¬¸ ì™¸ì— ë‹¤ë¥¸ ë§ì€ í•˜ì§€ ë§ˆì„¸ìš”.

ì§ˆë¬¸:`;

export const technicalQuestionAgent = async (state: InterviewState) => {
  console.log("ğŸ”§ Technical Question Agent generating question...");
  const { userContext, questions_asked } = state;

  const model = new ChatGoogleGenerativeAI({
    model: "gemini-2.0-flash",
    temperature: 0.7,
  });

  const formattedPrompt = technicalQuestionPrompt
    .replace("{jobRole}", userContext.jobRole)
    .replace("{experience}", userContext.experience)
    .replace("{interviewType}", userContext.interviewType)
    .replace("{questions_asked}", questions_asked.join(", ") || "ì—†ìŒ");

  const response = await model.invoke(formattedPrompt);
  const question = response.content.toString();

  console.log(`ğŸ”§ Technical question generated: ${question}`);
  return {
    messages: [new AIMessage(question)],
    current_question: question,
    questions_asked: [...questions_asked, question],
    interview_stage: "Questioning",
    next: "supervisor",
  };
}; 