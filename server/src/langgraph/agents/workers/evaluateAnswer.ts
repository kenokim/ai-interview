import { AIMessage, HumanMessage } from "@langchain/core/messages";
import { ChatGoogleGenerativeAI } from "@langchain/google-genai";
import { JsonOutputParser } from "@langchain/core/output_parsers";
import {
  InterviewState,
} from "../../../types/state.js";

interface Evaluation {
  score: number;
  reason: string;
}

const evaluationPrompt = `ë‹¹ì‹ ì€ ë©´ì ‘ê´€ì˜ ë‹µë³€ í‰ê°€ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ë‹¤ìŒ ì§ˆë¬¸ê³¼ í›„ë³´ìì˜ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ, ë‹µë³€ì´ ì–¼ë§ˆë‚˜ ì ì ˆí•œì§€ 1~5ì  ì²™ë„ë¡œ í‰ê°€í•˜ê³  ê·¸ ì´ìœ ë¥¼ ê°„ëµíˆ ì„¤ëª…í•´ ì£¼ì„¸ìš”.

ì§ˆë¬¸: {question}
ë‹µë³€: {answer}

ì¶œë ¥ í˜•ì‹ì€ ë°˜ë“œì‹œ ë‹¤ìŒ JSON ìŠ¤í‚¤ë§ˆë¥¼ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤:
{
  "score": "1~5 ì‚¬ì´ì˜ ì •ìˆ˜",
  "reason": "í‰ê°€ ì´ìœ ë¥¼ í•œêµ­ì–´ë¡œ ê°„ëµíˆ ì„¤ëª…"
}

JSON ì¶œë ¥:`;

export const evaluateAnswerAgent = async (state: InterviewState) => {
  console.log("ğŸ§ Evaluating answer...");
  const { messages, current_question } = state;
  const lastMessage = messages[messages.length - 1];

  if (lastMessage instanceof AIMessage) {
    console.log("ğŸ§ Last message is from AI, no evaluation needed.");
    return { ...state };
  }

  const model = new ChatGoogleGenerativeAI({
    model: "gemini-2.0-flash",
    temperature: 0.2,
  }).pipe(new JsonOutputParser<Evaluation>());

  const formattedPrompt = evaluationPrompt
    .replace("{question}", current_question || "ì—†ìŒ")
    .replace("{answer}", lastMessage.content.toString());

  const response = await model.invoke(formattedPrompt);

  console.log(`ğŸ§ Evaluation result:`, response);

  return {
    last_evaluation: response,
    interview_stage: "Evaluating",
    next: "supervisor",
  };
}; 